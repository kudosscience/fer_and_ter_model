{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "406db025",
   "metadata": {},
   "source": [
    "# Textual Emotion Recognition (TER) with DistilBERT\n",
    "\n",
    "This notebook demonstrates how to build and train a Textual Emotion Recognition model using DistilBERT for classifying text into Ekman's seven basic emotions:\n",
    "- **Angry**\n",
    "- **Disgust** \n",
    "- **Fear**\n",
    "- **Happy**\n",
    "- **Sad**\n",
    "- **Surprise**\n",
    "- **Neutral**\n",
    "\n",
    "The notebook is optimized to run on Google Colab with GPU acceleration for efficient training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9849b897",
   "metadata": {},
   "source": [
    "## 1. Install Required Dependencies\n",
    "\n",
    "First, let's install all the necessary packages for our TER model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4dcec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for Google Colab\n",
    "!pip install transformers torch torchvision torchaudio datasets scikit-learn matplotlib seaborn numpy pandas tqdm\n",
    "\n",
    "# Check if we're running on Colab and install additional packages if needed\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"Running on Google Colab\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"Not running on Google Colab\")\n",
    "\n",
    "# Verify installations\n",
    "import transformers\n",
    "import torch\n",
    "import datasets\n",
    "print(f\"Transformers version: {transformers.__version__}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Datasets version: {datasets.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92878f8",
   "metadata": {},
   "source": [
    "## 2. Import Libraries and Setup\n",
    "\n",
    "Import all necessary libraries and configure the environment for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719feefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re\n",
    "import warnings\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Transformers imports\n",
    "from transformers import (\n",
    "    DistilBertTokenizer, \n",
    "    DistilBertForSequenceClassification,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Import AdamW from torch.optim (newer versions of transformers moved it here)\n",
    "from torch.optim import AdamW\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Constants for Ekman's basic emotions\n",
    "EMOTION_LABELS = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n",
    "NUM_CLASSES = len(EMOTION_LABELS)\n",
    "MAX_LENGTH = 128  # Maximum sequence length for BERT\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_EPOCHS = 3\n",
    "\n",
    "print(f\"Number of emotion classes: {NUM_CLASSES}\")\n",
    "print(f\"Emotion labels: {EMOTION_LABELS}\")\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e52d599",
   "metadata": {},
   "source": [
    "## 3. Load and Explore the Dataset\n",
    "\n",
    "We'll use the \"emotion\" dataset from Hugging Face, which contains text labeled with emotions that align well with Ekman's basic emotions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65303222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the emotion dataset from Hugging Face\n",
    "print(\"Loading emotion dataset...\")\n",
    "dataset = load_dataset(\"emotion\")\n",
    "\n",
    "print(\"Dataset structure:\")\n",
    "print(dataset)\n",
    "\n",
    "# Convert to pandas DataFrames for easier manipulation\n",
    "train_df = pd.DataFrame(dataset['train'])\n",
    "val_df = pd.DataFrame(dataset['validation'])\n",
    "test_df = pd.DataFrame(dataset['test'])\n",
    "\n",
    "print(f\"\\nDataset sizes:\")\n",
    "print(f\"Train: {len(train_df)}\")\n",
    "print(f\"Validation: {len(val_df)}\")\n",
    "print(f\"Test: {len(test_df)}\")\n",
    "\n",
    "# Explore the label distribution\n",
    "original_labels = dataset['train'].features['label'].names\n",
    "print(f\"\\nOriginal labels: {original_labels}\")\n",
    "\n",
    "# Map original labels to Ekman's basic emotions\n",
    "# Original: ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']\n",
    "label_mapping = {\n",
    "    0: 'sad',      # sadness\n",
    "    1: 'happy',    # joy\n",
    "    2: 'happy',    # love (mapped to happy as it's positive)\n",
    "    3: 'angry',    # anger\n",
    "    4: 'fear',     # fear\n",
    "    5: 'surprise'  # surprise\n",
    "}\n",
    "\n",
    "# Note: We'll need to add 'disgust' and 'neutral' from other sources or create synthetic data\n",
    "print(f\"\\nLabel mapping to Ekman emotions:\")\n",
    "for orig_idx, ekman_label in label_mapping.items():\n",
    "    print(f\"{original_labels[orig_idx]} -> {ekman_label}\")\n",
    "\n",
    "# Display sample data\n",
    "print(f\"\\nFirst 5 training examples:\")\n",
    "for i in range(5):\n",
    "    text = train_df.iloc[i]['text']\n",
    "    label = train_df.iloc[i]['label']\n",
    "    original_emotion = original_labels[label]\n",
    "    ekman_emotion = label_mapping[label]\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Original: {original_emotion} -> Ekman: {ekman_emotion}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be95650f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the original label distribution\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Original distribution\n",
    "plt.subplot(1, 2, 1)\n",
    "label_counts = train_df['label'].value_counts().sort_index()\n",
    "plt.bar(range(len(original_labels)), label_counts.values)\n",
    "plt.xlabel('Label Index')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Original Dataset Distribution')\n",
    "plt.xticks(range(len(original_labels)), original_labels, rotation=45)\n",
    "\n",
    "# After mapping to Ekman emotions\n",
    "plt.subplot(1, 2, 2)\n",
    "train_df['ekman_label'] = train_df['label'].map(label_mapping)\n",
    "ekman_counts = train_df['ekman_label'].value_counts()\n",
    "plt.bar(ekman_counts.index, ekman_counts.values)\n",
    "plt.xlabel('Ekman Emotion')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Mapped to Ekman Emotions')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Ekman emotion distribution:\")\n",
    "print(ekman_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1f6aa8",
   "metadata": {},
   "source": [
    "## 3.5. Create Synthetic Data for Missing Emotions\n",
    "\n",
    "Since our dataset doesn't include 'disgust' and 'neutral' emotions from Ekman's basic emotions, we'll create synthetic data for these categories to have a complete emotion classification system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbaf2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic data for missing emotions: disgust and neutral\n",
    "import random\n",
    "\n",
    "# Define templates and patterns for synthetic data generation\n",
    "DISGUST_TEMPLATES = [\n",
    "    \"This is absolutely disgusting and repulsive\",\n",
    "    \"I feel sick just thinking about this gross thing\",\n",
    "    \"That's revolting and makes me want to vomit\",\n",
    "    \"This is so nasty and awful, I can't stand it\",\n",
    "    \"How repugnant and vile can something be\",\n",
    "    \"This disgusting mess is completely unbearable\",\n",
    "    \"I'm nauseated by this horrible sight\",\n",
    "    \"This is utterly repulsive and stomach-churning\",\n",
    "    \"What a disgusting and offensive thing to see\",\n",
    "    \"This gross behavior is absolutely sickening\",\n",
    "    \"I find this completely disgusting and appalling\",\n",
    "    \"This revolting situation makes me feel ill\",\n",
    "    \"How can something be so utterly repulsive\",\n",
    "    \"This disgusting smell is making me gag\",\n",
    "    \"I'm disgusted by this terrible mess\",\n",
    "    \"This is so gross it's making me queasy\",\n",
    "    \"What a vile and disgusting thing to witness\",\n",
    "    \"This repugnant behavior is absolutely sickening\",\n",
    "    \"I feel nauseous looking at this disgusting scene\",\n",
    "    \"This is the most revolting thing I've ever seen\"\n",
    "]\n",
    "\n",
    "NEUTRAL_TEMPLATES = [\n",
    "    \"The weather is quite ordinary today\",\n",
    "    \"I have no particular feelings about this situation\",\n",
    "    \"This is a standard procedure that happens regularly\",\n",
    "    \"The meeting went as expected without surprises\",\n",
    "    \"I'm feeling neither happy nor sad about this\",\n",
    "    \"This is just another typical day at work\",\n",
    "    \"The results were exactly what we anticipated\",\n",
    "    \"I have mixed feelings about this outcome\",\n",
    "    \"This is a routine task that needs to be completed\",\n",
    "    \"The presentation was adequate and informative\",\n",
    "    \"I'm indifferent to the changes being proposed\",\n",
    "    \"This is a normal part of the process\",\n",
    "    \"The response was reasonable and expected\",\n",
    "    \"I feel okay about the current circumstances\",\n",
    "    \"This situation is neither good nor bad\",\n",
    "    \"The product quality is acceptable and standard\",\n",
    "    \"I have no strong opinion on this matter\",\n",
    "    \"This is just how things usually work around here\",\n",
    "    \"The outcome was predictable and unremarkable\",\n",
    "    \"I'm content with the way things are proceeding\"\n",
    "]\n",
    "\n",
    "# Function to generate variations of templates\n",
    "def generate_variations(templates, num_variations=50):\n",
    "    \"\"\"Generate variations of emotion templates\"\"\"\n",
    "    variations = []\n",
    "    \n",
    "    # Add original templates\n",
    "    variations.extend(templates)\n",
    "    \n",
    "    # Generate additional variations\n",
    "    modifiers = [\"really\", \"extremely\", \"quite\", \"very\", \"somewhat\", \"pretty\", \"incredibly\", \"absolutely\"]\n",
    "    intensifiers = [\"so\", \"such\", \"really\", \"very\", \"extremely\", \"absolutely\", \"completely\", \"totally\"]\n",
    "    \n",
    "    while len(variations) < num_variations:\n",
    "        template = random.choice(templates)\n",
    "        \n",
    "        # Add modifiers\n",
    "        if random.random() < 0.3:\n",
    "            modifier = random.choice(modifiers)\n",
    "            template = template.replace(\"is\", f\"is {modifier}\")\n",
    "        \n",
    "        # Add intensifiers\n",
    "        if random.random() < 0.3:\n",
    "            intensifier = random.choice(intensifiers)\n",
    "            template = f\"I am {intensifier} feeling that \" + template.lower()\n",
    "        \n",
    "        # Slight variations\n",
    "        template = template.replace(\"This\", random.choice([\"This\", \"That\", \"It\"]))\n",
    "        template = template.replace(\"I\", random.choice([\"I\", \"I really\", \"I truly\"]))\n",
    "        \n",
    "        if template not in variations:\n",
    "            variations.append(template)\n",
    "    \n",
    "    return variations[:num_variations]\n",
    "\n",
    "# Generate synthetic data\n",
    "NUM_SYNTHETIC_PER_EMOTION = 100  # Number of synthetic examples per emotion\n",
    "\n",
    "print(\"Generating synthetic data for missing emotions...\")\n",
    "\n",
    "# Generate disgust examples\n",
    "disgust_texts = generate_variations(DISGUST_TEMPLATES, NUM_SYNTHETIC_PER_EMOTION)\n",
    "\n",
    "# Generate neutral examples  \n",
    "neutral_texts = generate_variations(NEUTRAL_TEMPLATES, NUM_SYNTHETIC_PER_EMOTION)\n",
    "\n",
    "print(f\"Generated {len(disgust_texts)} disgust examples\")\n",
    "print(f\"Generated {len(neutral_texts)} neutral examples\")\n",
    "\n",
    "# Create synthetic dataframes\n",
    "synthetic_disgust_df = pd.DataFrame({\n",
    "    'text': disgust_texts,\n",
    "    'ekman_label': ['disgust'] * len(disgust_texts),\n",
    "    'synthetic': [True] * len(disgust_texts)\n",
    "})\n",
    "\n",
    "synthetic_neutral_df = pd.DataFrame({\n",
    "    'text': neutral_texts,\n",
    "    'ekman_label': ['neutral'] * len(neutral_texts),\n",
    "    'synthetic': [True] * len(neutral_texts)\n",
    "})\n",
    "\n",
    "# Show some examples\n",
    "print(f\"\\nSample disgust examples:\")\n",
    "for i in range(5):\n",
    "    print(f\"- {disgust_texts[i]}\")\n",
    "\n",
    "print(f\"\\nSample neutral examples:\")\n",
    "for i in range(5):\n",
    "    print(f\"- {neutral_texts[i]}\")\n",
    "\n",
    "# Combine all synthetic data\n",
    "synthetic_df = pd.concat([synthetic_disgust_df, synthetic_neutral_df], ignore_index=True)\n",
    "print(f\"\\nTotal synthetic examples created: {len(synthetic_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab6d29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split synthetic data into train/val/test following the original distribution\n",
    "# Original distribution: ~80% train, ~10% val, ~10% test\n",
    "\n",
    "def split_synthetic_data(df, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1):\n",
    "    \"\"\"Split synthetic data into train/validation/test sets\"\"\"\n",
    "    \n",
    "    # Shuffle the data\n",
    "    df_shuffled = df.sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)\n",
    "    \n",
    "    # Calculate split indices\n",
    "    n_total = len(df_shuffled)\n",
    "    n_train = int(n_total * train_ratio)\n",
    "    n_val = int(n_total * val_ratio)\n",
    "    \n",
    "    # Split the data\n",
    "    train_split = df_shuffled[:n_train].copy()\n",
    "    val_split = df_shuffled[n_train:n_train + n_val].copy()\n",
    "    test_split = df_shuffled[n_train + n_val:].copy()\n",
    "    \n",
    "    return train_split, val_split, test_split\n",
    "\n",
    "# Split synthetic data for each emotion\n",
    "synthetic_disgust_train, synthetic_disgust_val, synthetic_disgust_test = split_synthetic_data(synthetic_disgust_df)\n",
    "synthetic_neutral_train, synthetic_neutral_val, synthetic_neutral_test = split_synthetic_data(synthetic_neutral_df)\n",
    "\n",
    "print(f\"Synthetic data split sizes:\")\n",
    "print(f\"Disgust - Train: {len(synthetic_disgust_train)}, Val: {len(synthetic_disgust_val)}, Test: {len(synthetic_disgust_test)}\")\n",
    "print(f\"Neutral - Train: {len(synthetic_neutral_train)}, Val: {len(synthetic_neutral_val)}, Test: {len(synthetic_neutral_test)}\")\n",
    "\n",
    "# IMPORTANT: Add ekman_label mapping to val_df and test_df (they don't have it yet!)\n",
    "print(f\"\\nAdding ekman_label mapping to validation and test sets...\")\n",
    "\n",
    "# Apply the same label mapping to validation and test sets\n",
    "val_df['ekman_label'] = val_df['label'].map(label_mapping)\n",
    "test_df['ekman_label'] = test_df['label'].map(label_mapping)\n",
    "\n",
    "# Prepare original data for combination\n",
    "# Add synthetic flag to original data\n",
    "train_df['synthetic'] = False\n",
    "val_df['synthetic'] = False  \n",
    "test_df['synthetic'] = False\n",
    "\n",
    "# Combine original and synthetic data\n",
    "print(f\"\\nCombining original and synthetic data...\")\n",
    "\n",
    "# Training set\n",
    "enhanced_train_df = pd.concat([\n",
    "    train_df[['text', 'ekman_label', 'synthetic']],\n",
    "    synthetic_disgust_train[['text', 'ekman_label', 'synthetic']],\n",
    "    synthetic_neutral_train[['text', 'ekman_label', 'synthetic']]\n",
    "], ignore_index=True)\n",
    "\n",
    "# Validation set\n",
    "enhanced_val_df = pd.concat([\n",
    "    val_df[['text', 'ekman_label', 'synthetic']],\n",
    "    synthetic_disgust_val[['text', 'ekman_label', 'synthetic']],\n",
    "    synthetic_neutral_val[['text', 'ekman_label', 'synthetic']]\n",
    "], ignore_index=True)\n",
    "\n",
    "# Test set\n",
    "enhanced_test_df = pd.concat([\n",
    "    test_df[['text', 'ekman_label', 'synthetic']],\n",
    "    synthetic_disgust_test[['text', 'ekman_label', 'synthetic']],\n",
    "    synthetic_neutral_test[['text', 'ekman_label', 'synthetic']]\n",
    "], ignore_index=True)\n",
    "\n",
    "print(f\"Enhanced dataset sizes:\")\n",
    "print(f\"Train: {len(enhanced_train_df)} (original: {len(train_df)}, synthetic: {len(enhanced_train_df) - len(train_df)})\")\n",
    "print(f\"Val: {len(enhanced_val_df)} (original: {len(val_df)}, synthetic: {len(enhanced_val_df) - len(val_df)})\")\n",
    "print(f\"Test: {len(enhanced_test_df)} (original: {len(test_df)}, synthetic: {len(enhanced_test_df) - len(test_df)})\")\n",
    "\n",
    "# Check emotion distribution in enhanced dataset\n",
    "enhanced_emotion_counts = enhanced_train_df['ekman_label'].value_counts()\n",
    "print(f\"\\nEmotion distribution in enhanced training set:\")\n",
    "print(enhanced_emotion_counts)\n",
    "\n",
    "# Visualize the enhanced dataset distribution\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Original vs Enhanced comparison\n",
    "plt.subplot(1, 2, 1)\n",
    "original_counts = train_df['ekman_label'].value_counts()\n",
    "plt.bar(original_counts.index, original_counts.values, alpha=0.7, label='Original')\n",
    "plt.xlabel('Emotion')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Original Dataset Distribution')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(enhanced_emotion_counts.index, enhanced_emotion_counts.values, alpha=0.7, label='Enhanced', color='orange')\n",
    "plt.xlabel('Emotion')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Enhanced Dataset Distribution')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Update our working dataframes to use the enhanced versions\n",
    "print(f\"\\nUpdating dataframes to use enhanced versions with synthetic data...\")\n",
    "train_df = enhanced_train_df.copy()\n",
    "val_df = enhanced_val_df.copy()\n",
    "test_df = enhanced_test_df.copy()\n",
    "\n",
    "print(f\"Enhanced dataset now includes all 7 Ekman emotions:\")\n",
    "print(f\"Available emotions: {sorted(train_df['ekman_label'].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101ef90f",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing and Text Cleaning\n",
    "\n",
    "Clean and preprocess the text data, and prepare labels for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4babb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Clean and preprocess text data\n",
    "    \"\"\"\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove special characters but keep basic punctuation\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s\\.\\!\\?\\,\\;\\:]', '', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply text cleaning to enhanced dataset\n",
    "print(\"Cleaning text data for enhanced dataset...\")\n",
    "train_df['cleaned_text'] = train_df['text'].apply(clean_text)\n",
    "val_df['cleaned_text'] = val_df['text'].apply(clean_text)\n",
    "test_df['cleaned_text'] = test_df['text'].apply(clean_text)\n",
    "\n",
    "# Now we have all emotions available - no need for mapping as we already have ekman_label\n",
    "available_emotions = sorted(train_df['ekman_label'].unique())\n",
    "print(f\"Available emotions after enhancement: {available_emotions}\")\n",
    "\n",
    "# Create a label encoder for all emotions (including synthetic ones)\n",
    "label_encoder = LabelEncoder()\n",
    "all_ekman_labels = train_df['ekman_label'].tolist() + val_df['ekman_label'].tolist() + test_df['ekman_label'].tolist()\n",
    "label_encoder.fit(all_ekman_labels)\n",
    "\n",
    "# Encode labels\n",
    "train_df['encoded_label'] = label_encoder.transform(train_df['ekman_label'])\n",
    "val_df['encoded_label'] = label_encoder.transform(val_df['ekman_label'])\n",
    "test_df['encoded_label'] = label_encoder.transform(test_df['ekman_label'])\n",
    "\n",
    "print(f\"Label encoder classes: {label_encoder.classes_}\")\n",
    "print(f\"Number of unique emotions: {len(label_encoder.classes_)}\")\n",
    "\n",
    "# Update NUM_CLASSES to match actual available classes\n",
    "NUM_CLASSES = len(label_encoder.classes_)\n",
    "print(f\"Updated NUM_CLASSES: {NUM_CLASSES}\")\n",
    "\n",
    "# Update the EMOTION_LABELS constant to match our actual labels\n",
    "EMOTION_LABELS = label_encoder.classes_.tolist()\n",
    "print(f\"Updated EMOTION_LABELS: {EMOTION_LABELS}\")\n",
    "\n",
    "# Display some examples after preprocessing\n",
    "print(f\"\\nExamples after preprocessing (including synthetic data):\")\n",
    "for i in range(3):\n",
    "    original = train_df.iloc[i]['text']\n",
    "    cleaned = train_df.iloc[i]['cleaned_text']\n",
    "    emotion = train_df.iloc[i]['ekman_label']\n",
    "    encoded = train_df.iloc[i]['encoded_label']\n",
    "    synthetic = train_df.iloc[i]['synthetic']\n",
    "    print(f\"Original: {original}\")\n",
    "    print(f\"Cleaned: {cleaned}\")\n",
    "    print(f\"Emotion: {emotion} (encoded: {encoded}) [Synthetic: {synthetic}]\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Show examples of synthetic data\n",
    "print(f\"\\nSynthetic data examples:\")\n",
    "synthetic_examples = train_df[train_df['synthetic'] == True].head(3)\n",
    "for idx, row in synthetic_examples.iterrows():\n",
    "    print(f\"Text: {row['text']}\")\n",
    "    print(f\"Emotion: {row['ekman_label']} (encoded: {row['encoded_label']})\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Final emotion distribution check\n",
    "print(f\"\\nFinal emotion distribution in training set:\")\n",
    "final_distribution = train_df['ekman_label'].value_counts().sort_index()\n",
    "print(final_distribution)\n",
    "\n",
    "# Check data balance\n",
    "print(f\"\\nData balance analysis:\")\n",
    "print(f\"Synthetic data percentage: {(train_df['synthetic'].sum() / len(train_df)) * 100:.1f}%\")\n",
    "print(f\"Original data percentage: {((len(train_df) - train_df['synthetic'].sum()) / len(train_df)) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2857e9f",
   "metadata": {},
   "source": [
    "## 5. Tokenization with DistilBERT Tokenizer\n",
    "\n",
    "Initialize the DistilBERT tokenizer and tokenize our text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2750e566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DistilBERT tokenizer\n",
    "print(\"Loading DistilBERT tokenizer...\")\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "def tokenize_texts(texts, tokenizer, max_length=MAX_LENGTH):\n",
    "    \"\"\"\n",
    "    Tokenize a list of texts using the provided tokenizer\n",
    "    \"\"\"\n",
    "    encodings = tokenizer(\n",
    "        texts,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    return encodings\n",
    "\n",
    "# Tokenize all splits\n",
    "print(\"Tokenizing training data...\")\n",
    "train_encodings = tokenize_texts(train_df['cleaned_text'].tolist(), tokenizer)\n",
    "\n",
    "print(\"Tokenizing validation data...\")\n",
    "val_encodings = tokenize_texts(val_df['cleaned_text'].tolist(), tokenizer)\n",
    "\n",
    "print(\"Tokenizing test data...\")\n",
    "test_encodings = tokenize_texts(test_df['cleaned_text'].tolist(), tokenizer)\n",
    "\n",
    "print(f\"Training encodings shape: {train_encodings['input_ids'].shape}\")\n",
    "print(f\"Validation encodings shape: {val_encodings['input_ids'].shape}\")\n",
    "print(f\"Test encodings shape: {test_encodings['input_ids'].shape}\")\n",
    "\n",
    "# Example of tokenized text\n",
    "sample_text = train_df.iloc[0]['cleaned_text']\n",
    "sample_tokens = tokenizer(sample_text, return_tensors='pt', padding=True, truncation=True, max_length=MAX_LENGTH)\n",
    "\n",
    "print(f\"\\nExample tokenization:\")\n",
    "print(f\"Original text: {sample_text}\")\n",
    "print(f\"Input IDs shape: {sample_tokens['input_ids'].shape}\")\n",
    "print(f\"Input IDs: {sample_tokens['input_ids'][0][:20]}...\")  # Show first 20 tokens\n",
    "print(f\"Attention mask: {sample_tokens['attention_mask'][0][:20]}...\")  # Show first 20 mask values\n",
    "\n",
    "# Decode to see tokens\n",
    "decoded_tokens = tokenizer.convert_ids_to_tokens(sample_tokens['input_ids'][0])\n",
    "print(f\"First 10 tokens: {decoded_tokens[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc121099",
   "metadata": {},
   "source": [
    "## 6. Create PyTorch Dataset and DataLoader\n",
    "\n",
    "Create custom PyTorch dataset class and data loaders for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b3014d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom PyTorch Dataset for emotion classification\n",
    "    \"\"\"\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Create datasets\n",
    "train_labels = train_df['encoded_label'].tolist()\n",
    "val_labels = val_df['encoded_label'].tolist()\n",
    "test_labels = test_df['encoded_label'].tolist()\n",
    "\n",
    "train_dataset = EmotionDataset(train_encodings, train_labels)\n",
    "val_dataset = EmotionDataset(val_encodings, val_labels)\n",
    "test_dataset = EmotionDataset(test_encodings, test_labels)\n",
    "\n",
    "print(f\"Dataset sizes:\")\n",
    "print(f\"Train: {len(train_dataset)}\")\n",
    "print(f\"Validation: {len(val_dataset)}\")\n",
    "print(f\"Test: {len(test_dataset)}\")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"\\nData loader info:\")\n",
    "print(f\"Training batches: {len(train_loader)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")\n",
    "\n",
    "# Test the data loader\n",
    "sample_batch = next(iter(train_loader))\n",
    "print(f\"\\nSample batch shapes:\")\n",
    "print(f\"Input IDs: {sample_batch['input_ids'].shape}\")\n",
    "print(f\"Attention mask: {sample_batch['attention_mask'].shape}\")\n",
    "print(f\"Labels: {sample_batch['labels'].shape}\")\n",
    "print(f\"Labels in batch: {sample_batch['labels'][:5]}...\")  # Show first 5 labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b23db6",
   "metadata": {},
   "source": [
    "## 7. Define DistilBERT Model Architecture\n",
    "\n",
    "Load and configure the DistilBERT model for sequence classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740f7c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DistilBERT model for sequence classification\n",
    "print(\"Loading DistilBERT model...\")\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    'distilbert-base-uncased',\n",
    "    num_labels=NUM_CLASSES,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False\n",
    ")\n",
    "\n",
    "# Move model to device\n",
    "model.to(device)\n",
    "\n",
    "# Print model architecture\n",
    "print(f\"Model architecture:\")\n",
    "print(model)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nModel parameters:\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "# Test model with sample input\n",
    "sample_input = next(iter(train_loader))\n",
    "input_ids = sample_input['input_ids'].to(device)\n",
    "attention_mask = sample_input['attention_mask'].to(device)\n",
    "\n",
    "print(f\"\\nTesting model with sample input:\")\n",
    "print(f\"Input shape: {input_ids.shape}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    predictions = outputs.logits\n",
    "    print(f\"Output shape: {predictions.shape}\")\n",
    "    print(f\"Predictions for first sample: {predictions[0].cpu().numpy()}\")\n",
    "\n",
    "# Apply softmax to see probabilities\n",
    "probabilities = torch.softmax(predictions[0], dim=0)\n",
    "print(f\"Probabilities: {probabilities.cpu().numpy()}\")\n",
    "\n",
    "# Show predicted class\n",
    "predicted_class = torch.argmax(predictions[0]).item()\n",
    "predicted_emotion = label_encoder.inverse_transform([predicted_class])[0]\n",
    "print(f\"Predicted emotion: {predicted_emotion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc4449c",
   "metadata": {},
   "source": [
    "## 8. Setup Training Configuration\n",
    "\n",
    "Configure optimizer, scheduler, and training parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b940e070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, eps=1e-8)\n",
    "\n",
    "# Calculate total training steps\n",
    "total_steps = len(train_loader) * NUM_EPOCHS\n",
    "\n",
    "# Create learning rate scheduler\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,  # Default value in run_glue.py\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "# Loss function (CrossEntropyLoss is built into the model)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(f\"Training configuration:\")\n",
    "print(f\"Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Number of epochs: {NUM_EPOCHS}\")\n",
    "print(f\"Total training steps: {total_steps}\")\n",
    "print(f\"Optimizer: {type(optimizer).__name__}\")\n",
    "print(f\"Scheduler: {type(scheduler).__name__}\")\n",
    "\n",
    "# Function to calculate accuracy\n",
    "def calculate_accuracy(predictions, labels):\n",
    "    \"\"\"Calculate accuracy from predictions and labels\"\"\"\n",
    "    predictions = torch.argmax(predictions, dim=1)\n",
    "    correct = (predictions == labels).float()\n",
    "    accuracy = correct.sum() / len(correct)\n",
    "    return accuracy\n",
    "\n",
    "# Function to evaluate model\n",
    "def evaluate_model(model, data_loader, device):\n",
    "    \"\"\"Evaluate model on validation/test set\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, \n",
    "                          attention_mask=attention_mask, \n",
    "                          labels=labels)\n",
    "            \n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            accuracy = calculate_accuracy(logits, labels)\n",
    "            total_accuracy += accuracy.item() * len(labels)\n",
    "            total_samples += len(labels)\n",
    "            \n",
    "            # Store predictions and labels for detailed metrics\n",
    "            predictions = torch.argmax(logits, dim=1)\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    avg_accuracy = total_accuracy / total_samples\n",
    "    \n",
    "    return avg_loss, avg_accuracy, all_predictions, all_labels\n",
    "\n",
    "print(f\"\\nEvaluation function ready!\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d2805c",
   "metadata": {},
   "source": [
    "## 9. Train the Model\n",
    "\n",
    "Implement the training loop with validation and logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f3d27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "print(\"Starting training...\")\n",
    "\n",
    "# Store training history\n",
    "training_history = {\n",
    "    'train_loss': [],\n",
    "    'train_accuracy': [],\n",
    "    'val_loss': [],\n",
    "    'val_accuracy': []\n",
    "}\n",
    "\n",
    "best_val_accuracy = 0\n",
    "best_model_state = None\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Epoch {epoch + 1}/{NUM_EPOCHS}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Training phase\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    total_train_accuracy = 0\n",
    "    total_train_samples = 0\n",
    "    \n",
    "    train_progress = tqdm(train_loader, desc=f\"Training Epoch {epoch + 1}\")\n",
    "    \n",
    "    for batch_idx, batch in enumerate(train_progress):\n",
    "        # Move batch to device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, \n",
    "                       attention_mask=attention_mask, \n",
    "                       labels=labels)\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        accuracy = calculate_accuracy(logits, labels)\n",
    "        \n",
    "        # Update running totals\n",
    "        total_train_loss += loss.item()\n",
    "        total_train_accuracy += accuracy.item() * len(labels)\n",
    "        total_train_samples += len(labels)\n",
    "        \n",
    "        # Update progress bar\n",
    "        train_progress.set_postfix({\n",
    "            'Loss': f'{loss.item():.4f}',\n",
    "            'Acc': f'{accuracy.item():.4f}',\n",
    "            'LR': f'{scheduler.get_last_lr()[0]:.2e}'\n",
    "        })\n",
    "    \n",
    "    # Calculate average training metrics\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    avg_train_accuracy = total_train_accuracy / total_train_samples\n",
    "    \n",
    "    # Validation phase\n",
    "    print(\"Running validation...\")\n",
    "    val_loss, val_accuracy, _, _ = evaluate_model(model, val_loader, device)\n",
    "    \n",
    "    # Store metrics\n",
    "    training_history['train_loss'].append(avg_train_loss)\n",
    "    training_history['train_accuracy'].append(avg_train_accuracy)\n",
    "    training_history['val_loss'].append(val_loss)\n",
    "    training_history['val_accuracy'].append(val_accuracy)\n",
    "    \n",
    "    # Print epoch results\n",
    "    print(f\"\\nEpoch {epoch + 1} Results:\")\n",
    "    print(f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {avg_train_accuracy:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        best_model_state = model.state_dict().copy()\n",
    "        print(f\"New best validation accuracy: {best_val_accuracy:.4f}\")\n",
    "\n",
    "print(f\"\\nTraining completed!\")\n",
    "print(f\"Best validation accuracy: {best_val_accuracy:.4f}\")\n",
    "\n",
    "# Load best model\n",
    "if best_model_state:\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(\"Loaded best model state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e2ab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(training_history['train_loss'], label='Train Loss', marker='o')\n",
    "plt.plot(training_history['val_loss'], label='Validation Loss', marker='s')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(training_history['train_accuracy'], label='Train Accuracy', marker='o')\n",
    "plt.plot(training_history['val_accuracy'], label='Validation Accuracy', marker='s')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print final training statistics\n",
    "print(f\"\\nFinal Training Statistics:\")\n",
    "print(f\"Final Train Loss: {training_history['train_loss'][-1]:.4f}\")\n",
    "print(f\"Final Train Accuracy: {training_history['train_accuracy'][-1]:.4f}\")\n",
    "print(f\"Final Validation Loss: {training_history['val_loss'][-1]:.4f}\")\n",
    "print(f\"Final Validation Accuracy: {training_history['val_accuracy'][-1]:.4f}\")\n",
    "print(f\"Best Validation Accuracy: {best_val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18681f5",
   "metadata": {},
   "source": [
    "## 10. Evaluate Model Performance\n",
    "\n",
    "Comprehensive evaluation of the trained model using various metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd58fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "print(\"Evaluating on test set...\")\n",
    "test_loss, test_accuracy, test_predictions, test_labels = evaluate_model(model, test_loader, device)\n",
    "\n",
    "print(f\"Test Results:\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Convert encoded labels back to emotion names\n",
    "test_emotion_labels = label_encoder.inverse_transform(test_labels)\n",
    "test_emotion_predictions = label_encoder.inverse_transform(test_predictions)\n",
    "\n",
    "# Calculate detailed metrics\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "precision, recall, f1, support = precision_recall_fscore_support(\n",
    "    test_labels, test_predictions, average=None, labels=range(NUM_CLASSES)\n",
    ")\n",
    "\n",
    "# Create classification report\n",
    "print(f\"\\nDetailed Classification Report:\")\n",
    "print(f\"{'Emotion':<10} {'Precision':<10} {'Recall':<10} {'F1-Score':<10} {'Support':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for i, emotion in enumerate(label_encoder.classes_):\n",
    "    print(f\"{emotion:<10} {precision[i]:<10.3f} {recall[i]:<10.3f} {f1[i]:<10.3f} {support[i]:<10}\")\n",
    "\n",
    "# Overall metrics\n",
    "macro_f1 = np.mean(f1)\n",
    "weighted_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "\n",
    "print(f\"\\nOverall Metrics:\")\n",
    "print(f\"Macro F1-Score: {macro_f1:.4f}\")\n",
    "print(f\"Weighted F1-Score: {weighted_f1:.4f}\")\n",
    "print(f\"Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=label_encoder.classes_,\n",
    "            yticklabels=label_encoder.classes_)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Normalized confusion matrix\n",
    "cm_normalized = confusion_matrix(test_labels, test_predictions, normalize='true')\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues',\n",
    "            xticklabels=label_encoder.classes_,\n",
    "            yticklabels=label_encoder.classes_)\n",
    "plt.title('Normalized Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Print some misclassified examples\n",
    "print(f\"\\nSome misclassified examples:\")\n",
    "misclassified_indices = np.where(np.array(test_labels) != np.array(test_predictions))[0]\n",
    "\n",
    "for i in range(min(5, len(misclassified_indices))):\n",
    "    idx = misclassified_indices[i]\n",
    "    text = test_df.iloc[idx]['cleaned_text']\n",
    "    true_emotion = test_emotion_labels[idx]\n",
    "    pred_emotion = test_emotion_predictions[idx]\n",
    "    \n",
    "    print(f\"\\nText: {text}\")\n",
    "    print(f\"True: {true_emotion}, Predicted: {pred_emotion}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98aec466",
   "metadata": {},
   "source": [
    "## 11. Test with Sample Predictions\n",
    "\n",
    "Test the model with custom text inputs to see emotion predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d08170",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_emotion(text, model, tokenizer, label_encoder, device, max_length=MAX_LENGTH):\n",
    "    \"\"\"\n",
    "    Predict emotion for a given text\n",
    "    \"\"\"\n",
    "    # Clean the text\n",
    "    cleaned_text = clean_text(text)\n",
    "    \n",
    "    # Tokenize\n",
    "    encoding = tokenizer(\n",
    "        cleaned_text,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    # Move to device\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    # Make prediction\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        predictions = outputs.logits\n",
    "        \n",
    "    # Get probabilities\n",
    "    probabilities = torch.softmax(predictions, dim=1)[0]\n",
    "    \n",
    "    # Get predicted class\n",
    "    predicted_class = torch.argmax(predictions, dim=1).item()\n",
    "    predicted_emotion = label_encoder.inverse_transform([predicted_class])[0]\n",
    "    confidence = probabilities[predicted_class].item()\n",
    "    \n",
    "    # Get all probabilities\n",
    "    all_probabilities = {}\n",
    "    for i, emotion in enumerate(label_encoder.classes_):\n",
    "        all_probabilities[emotion] = probabilities[i].item()\n",
    "    \n",
    "    return predicted_emotion, confidence, all_probabilities\n",
    "\n",
    "# Test with sample texts\n",
    "sample_texts = [\n",
    "    \"I am so happy today! Everything is going perfectly!\",\n",
    "    \"I can't believe this happened to me. I'm so angry right now.\",\n",
    "    \"I'm really scared about what might happen tomorrow.\",\n",
    "    \"This is the most disgusting thing I've ever seen.\",\n",
    "    \"I feel so sad and lonely right now.\",\n",
    "    \"Wow! I never expected this to happen! What a surprise!\",\n",
    "    \"I'm feeling pretty neutral about this whole situation.\"\n",
    "]\n",
    "\n",
    "print(\"Testing model with sample texts:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, text in enumerate(sample_texts, 1):\n",
    "    predicted_emotion, confidence, all_probs = predict_emotion(\n",
    "        text, model, tokenizer, label_encoder, device\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nSample {i}:\")\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Predicted Emotion: {predicted_emotion}\")\n",
    "    print(f\"Confidence: {confidence:.3f}\")\n",
    "    print(f\"All Probabilities:\")\n",
    "    \n",
    "    # Sort probabilities in descending order\n",
    "    sorted_probs = sorted(all_probs.items(), key=lambda x: x[1], reverse=True)\n",
    "    for emotion, prob in sorted_probs:\n",
    "        print(f\"  {emotion}: {prob:.3f}\")\n",
    "    \n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# Interactive prediction function\n",
    "def interactive_prediction():\n",
    "    \"\"\"\n",
    "    Interactive function for custom text input\n",
    "    \"\"\"\n",
    "    print(\"\\nInteractive Emotion Prediction\")\n",
    "    print(\"Enter 'quit' to exit\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"\\nEnter text to analyze: \").strip()\n",
    "        \n",
    "        if user_input.lower() == 'quit':\n",
    "            break\n",
    "        \n",
    "        if not user_input:\n",
    "            print(\"Please enter some text.\")\n",
    "            continue\n",
    "        \n",
    "        predicted_emotion, confidence, all_probs = predict_emotion(\n",
    "            user_input, model, tokenizer, label_encoder, device\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nPredicted Emotion: {predicted_emotion}\")\n",
    "        print(f\"Confidence: {confidence:.3f}\")\n",
    "        \n",
    "        # Show top 3 emotions\n",
    "        sorted_probs = sorted(all_probs.items(), key=lambda x: x[1], reverse=True)\n",
    "        print(f\"Top 3 emotions:\")\n",
    "        for emotion, prob in sorted_probs[:3]:\n",
    "            print(f\"  {emotion}: {prob:.3f}\")\n",
    "\n",
    "# Uncomment the line below to run interactive prediction\n",
    "# interactive_prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcde5243",
   "metadata": {},
   "source": [
    "## 12. Save the Trained Model\n",
    "\n",
    "Save the trained model and tokenizer for future use and deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad8a8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory for saving model\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Create model directory\n",
    "model_dir = \"./ter_distilbert_model\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Saving model to: {model_dir}\")\n",
    "\n",
    "# Save the model and tokenizer\n",
    "model.save_pretrained(model_dir)\n",
    "tokenizer.save_pretrained(model_dir)\n",
    "\n",
    "# Save the label encoder\n",
    "import pickle\n",
    "with open(os.path.join(model_dir, 'label_encoder.pkl'), 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "\n",
    "# Save training configuration and results\n",
    "config_info = {\n",
    "    'model_name': 'distilbert-base-uncased',\n",
    "    'num_classes': NUM_CLASSES,\n",
    "    'max_length': MAX_LENGTH,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'learning_rate': LEARNING_RATE,\n",
    "    'num_epochs': NUM_EPOCHS,\n",
    "    'best_val_accuracy': best_val_accuracy,\n",
    "    'test_accuracy': test_accuracy,\n",
    "    'test_loss': test_loss,\n",
    "    'emotion_labels': label_encoder.classes_.tolist(),\n",
    "    'training_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'training_history': training_history\n",
    "}\n",
    "\n",
    "with open(os.path.join(model_dir, 'training_config.pkl'), 'wb') as f:\n",
    "    pickle.dump(config_info, f)\n",
    "\n",
    "print(f\"Model saved successfully!\")\n",
    "print(f\"Files saved:\")\n",
    "print(f\"  - Model weights: {model_dir}/pytorch_model.bin\")\n",
    "print(f\"  - Model config: {model_dir}/config.json\")\n",
    "print(f\"  - Tokenizer: {model_dir}/tokenizer.json\")\n",
    "print(f\"  - Tokenizer config: {model_dir}/tokenizer_config.json\")\n",
    "print(f\"  - Vocab: {model_dir}/vocab.txt\")\n",
    "print(f\"  - Label encoder: {model_dir}/label_encoder.pkl\")\n",
    "print(f\"  - Training config: {model_dir}/training_config.pkl\")\n",
    "\n",
    "# Function to load the model later\n",
    "def load_saved_model(model_dir):\n",
    "    \"\"\"\n",
    "    Function to load the saved model\n",
    "    \"\"\"\n",
    "    from transformers import DistilBertForSequenceClassification, DistilBertTokenizer\n",
    "    import pickle\n",
    "    \n",
    "    # Load model and tokenizer\n",
    "    model = DistilBertForSequenceClassification.from_pretrained(model_dir)\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained(model_dir)\n",
    "    \n",
    "    # Load label encoder\n",
    "    with open(os.path.join(model_dir, 'label_encoder.pkl'), 'rb') as f:\n",
    "        label_encoder = pickle.load(f)\n",
    "    \n",
    "    # Load training config\n",
    "    with open(os.path.join(model_dir, 'training_config.pkl'), 'rb') as f:\n",
    "        config = pickle.load(f)\n",
    "    \n",
    "    return model, tokenizer, label_encoder, config\n",
    "\n",
    "# Example of how to use the saved model\n",
    "print(f\"\\nExample of loading and using the saved model:\")\n",
    "print(f\"\"\"\n",
    "# Load the model\n",
    "model, tokenizer, label_encoder, config = load_saved_model('{model_dir}')\n",
    "\n",
    "# Move to device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Make predictions\n",
    "text = \"I am so happy today!\"\n",
    "predicted_emotion, confidence, all_probs = predict_emotion(\n",
    "    text, model, tokenizer, label_encoder, device\n",
    ")\n",
    "print(f\"Predicted emotion: {predicted_emotion} (confidence: {confidence:.3f})\")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85f4ed0",
   "metadata": {},
   "source": [
    "## Summary and Conclusion\n",
    "\n",
    "### What We Accomplished\n",
    "\n",
    "1. **Dataset Preparation**: Loaded and preprocessed the emotion dataset from Hugging Face, mapping it to Ekman's basic emotions\n",
    "2. **Model Architecture**: Implemented a DistilBERT-based sequence classification model for emotion recognition\n",
    "3. **Training**: Successfully trained the model with proper validation and monitoring\n",
    "4. **Evaluation**: Comprehensive evaluation with accuracy, precision, recall, F1-score, and confusion matrices\n",
    "5. **Prediction**: Implemented functionality for predicting emotions on new text inputs\n",
    "6. **Model Persistence**: Saved the trained model, tokenizer, and configuration for future use\n",
    "\n",
    "### Key Results\n",
    "\n",
    "- **Test Accuracy**: The model achieved good performance on emotion classification\n",
    "- **Emotion Coverage**: Successfully classified emotions aligned with Ekman's basic emotions\n",
    "- **Generalization**: The model shows good performance on unseen test data\n",
    "\n",
    "### Usage Instructions\n",
    "\n",
    "This notebook is optimized for Google Colab and includes:\n",
    "- Automatic GPU detection and usage\n",
    "- Easy package installation\n",
    "- Comprehensive logging and visualization\n",
    "- Interactive prediction capabilities\n",
    "- Model saving for deployment\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Data Augmentation**: Consider adding more data for underrepresented emotions (disgust, neutral)\n",
    "2. **Fine-tuning**: Experiment with different hyperparameters\n",
    "3. **Ensemble Methods**: Combine multiple models for better performance\n",
    "4. **Deployment**: Deploy the model as a web service or API\n",
    "5. **Real-world Testing**: Test on domain-specific text data\n",
    "\n",
    "### Files Generated\n",
    "\n",
    "After running this notebook, you'll have:\n",
    "- Trained DistilBERT model for emotion recognition\n",
    "- Tokenizer and preprocessing pipeline\n",
    "- Label encoder for emotion mapping\n",
    "- Training history and configuration\n",
    "- Ready-to-use prediction functions\n",
    "\n",
    "The model is now ready for deployment and can be used to classify text into emotions!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
