# Quick Start Guide for Dataset Setup

## ğŸ“ Directory Structure

```
ğŸ“¦ fer_and_ter_model/
â”œâ”€â”€ ğŸ“ data/                     # Main data directory
â”‚   â”œâ”€â”€ ğŸ“„ README.md             # Detailed documentation
â”‚   â”œâ”€â”€ ğŸ“ raw/                  # Raw, unprocessed data
â”‚   â”‚   â”œâ”€â”€ ğŸ“ fer_images/       # Facial emotion images
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ train/        # Training images
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ joy/      # Joy emotion images
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ anger/    # Anger emotion images  
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ disgust/  # Disgust emotion images
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ sadness/  # Sadness emotion images
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ fear/     # Fear emotion images
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“ surprise/ # Surprise emotion images
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ test/         # Test images (same structure)
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“ validation/   # Validation images (same structure)
â”‚   â”‚   â”œâ”€â”€ ğŸ“ text_data/        # Text emotion data
â”‚   â”‚   â””â”€â”€ ğŸ“ multimodal_data/  # Combined image+text data
â”‚   â””â”€â”€ ğŸ“ processed/            # Preprocessed features
â”‚       â”œâ”€â”€ ğŸ“ fer_features/     # Extracted FER features
â”‚       â””â”€â”€ ğŸ“ ter_features/     # Extracted TER features
â”œâ”€â”€ ğŸ“ models/                   # Saved trained models
â”œâ”€â”€ ğŸ“ results/                  # Training results and metrics
â”‚   â”œâ”€â”€ ğŸ“ plots/               # Generated plots and visualizations
â”‚   â””â”€â”€ ğŸ“ metrics/             # Performance metrics
â””â”€â”€ ğŸ“„ data_utils.py            # Dataset management utilities
```

## ğŸš€ Getting Started

### Step 1: Add Your Images
Place your facial emotion images in the appropriate directories:
- `data/raw/fer_images/train/joy/` - for joyful face images
- `data/raw/fer_images/train/anger/` - for angry face images  
- etc.

### Step 2: Create Text Data
Create JSON files following this format:
```json
[
  {
    "text": "I'm feeling great today!",
    "emotion": "joy",
    "id": "text_001"
  }
]
```

### Step 3: Create Multimodal Data
Link images with text using this format:
```json
[
  {
    "image_path": "data/raw/fer_images/train/joy/happy_face.jpg",
    "text": "I'm feeling great today!",
    "emotion": "joy", 
    "id": "multimodal_001"
  }
]
```

### Step 4: Use the Dataset Manager
Run the data utilities to check your dataset:
```bash
python data_utils.py
```

## ğŸ“Š Emotion Classes
The system supports 6 emotions:
- **joy** ğŸ˜Š - Happy, positive emotions
- **anger** ğŸ˜  - Angry, frustrated emotions  
- **disgust** ğŸ¤¢ - Disgusted, repulsed emotions
- **sadness** ğŸ˜¢ - Sad, depressed emotions
- **fear** ğŸ˜¨ - Fearful, anxious emotions
- **surprise** ğŸ˜² - Surprised, shocked emotions

## ğŸ’¡ Tips for Success

1. **Balance Your Data**: Aim for equal numbers of samples per emotion
2. **Quality Over Quantity**: Better to have fewer high-quality samples
3. **Test Split**: Keep 10-20% of data for final testing
4. **Validation Split**: Use 10-15% for hyperparameter tuning

## ğŸ“š Popular Datasets You Can Use

### Facial Emotion Recognition:
- **FER2013** - Classic facial emotion dataset
- **AffectNet** - Large-scale facial expressions
- **RAF-DB** - Real-world affective faces

### Text Emotion Recognition:
- **GoEmotions** - Google's emotion dataset  
- **SemEval-2018** - Emotion classification tasks
- **ISEAR** - International emotion survey

## ğŸ”§ Next Steps

1. **Collect/Download** your chosen dataset
2. **Organize** files into the created directory structure
3. **Run** `python data_utils.py` to validate your setup
4. **Train** your models using `python emotion-cnn-model.py`

## ğŸ“ Need Help?

- Check `data/README.md` for detailed documentation
- Use `data_utils.py` to manage and validate your dataset
- The system will automatically preprocess your data during training
